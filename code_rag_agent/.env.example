# ============================================================================
# API KEYS (REQUIRED)
# ============================================================================

# Google Gemini API Key (required for LLM)
GOOGLE_API_KEY=your_google_api_key_here

# ============================================================================
# REPOSITORY SETTINGS
# ============================================================================

# Path to httpx repository (relative to data/ directory)
HTTPX_REPO_DIR=httpx

# ============================================================================
# CHUNKING SETTINGS
# ============================================================================

# Chunking strategy: "ast" (recommended) or "window"
CHUNK_STRATEGY=ast

# Maximum chunk size in lines (for window strategy)
MAX_CHUNK_SIZE=500

# Chunk overlap in lines (for window strategy)
CHUNK_OVERLAP=50

# ============================================================================
# EMBEDDING SETTINGS
# ============================================================================

# Embedding model (local Hugging Face model)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Batch size for embedding generation
EMBEDDING_BATCH_SIZE=32

# ============================================================================
# RETRIEVAL SETTINGS
# ============================================================================

# Number of top results to retrieve
TOP_K=10

# Similarity threshold for filtering results
SIMILARITY_THRESHOLD=0.5

# Maximum number of retrieval iterations
MAX_ITERATIONS=3

# Hybrid search weights (must sum to 1.0)
VECTOR_WEIGHT=0.7
SPARSE_WEIGHT=0.3

# Enable reranking
RERANKING_ENABLED=true

# ============================================================================
# CONVERSATION MEMORY
# ============================================================================

# Maximum conversation history turns
MAX_HISTORY_TURNS=5

# Enable conversation memory
ENABLE_CONVERSATION_MEMORY=true

# ============================================================================
# LLM SETTINGS
# ============================================================================

# Primary LLM model
LLM_MODEL=gemini-2.0-flash

# Model tiers (fast/intermediate/slow)
MODEL_FAST=gemini-2.5-flash-lite
MODEL_INTERMEDIATE=gemini-2.5-flash
MODEL_SLOW=gemini-2.5-pro

# LLM parameters
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=2000
LLM_TIMEOUT=60
LLM_MAX_RETRIES=3
LLM_TOP_P=0.95
LLM_TOP_K=40

# ============================================================================
# LANGSMITH OBSERVABILITY (OPTIONAL)
# ============================================================================

# Enable LangSmith tracing
LANGCHAIN_TRACING_V2=false

# LangSmith API key
LANGCHAIN_API_KEY=

# LangSmith project name
LANGCHAIN_PROJECT=code-rag-agent

# ============================================================================
# OUTPUT SETTINGS
# ============================================================================

# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Show retrieval log in output
SHOW_RETRIEVAL_LOG=true

# Verbose output
VERBOSE_OUTPUT=false

# Enable streaming output
ENABLE_STREAMING=true

# Lazy initialization (load components on-demand)
LAZY_INITIALIZATION=true
